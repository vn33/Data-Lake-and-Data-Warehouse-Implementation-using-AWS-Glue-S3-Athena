# Data Lake and Data Warehouse Implementation

This project was completed as part of the **[Data Engineering by DeepLearning.AI & AWS](https://www.coursera.org/account/accomplishments/specialization/certificate/97VPY9BFR7Q2)** and focuses on building a data lake and querying data using AWS services.

## Project Overview

- **Data Lake**: Set up on Amazon S3 to store raw JSON files and processed data.
- **Data Transformation**: Used AWS Glue ETL to transform raw JSON files into a structured format.
- **Metadata Management**: Populated AWS Glue Data Catalog with metadata using Glue Crawler.
- **Data Querying**: Queried processed data stored in S3 using Amazon Athena for SQL-based analysis.

## Key Tools and Technologies

- **Amazon S3**: Primary storage for raw and processed data.
- **AWS Glue**: ETL transformations and metadata management.
- **Glue Crawler**: Automated schema discovery and catalog population.
- **Amazon Athena**: Query engine for data analysis using SQL.

## How to Run

1. **Set up an S3 Bucket**: Upload raw JSON files to the S3 bucket.
2. **AWS Glue ETL**: Create and run an ETL job to process and transform data.
3. **Glue Crawler**: Configure the Glue Crawler to populate the Data Catalog.
4. **Query with Athena**: Use SQL in Athena to analyze and retrieve insights from the processed data.

## Key Outcomes

- Demonstrated the creation and management of a simple data lake.
- Leveraged AWS Glue and Athena to perform efficient ETL and querying.
- Gained hands-on experience in AWS Data Engineering concepts.

